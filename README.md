# Generative-Perturbation-Networks

# Title
Generative Perturbation Network for Signal-Agnostic/Specific Adversarial Attacks on EEG-based Brain-Computer Interfaces

# Abstract
Brain-computer interface (BCI) enables direct communication between a brain and computers or external devices. Recently, deep neural networks (DNNs) have
achieved great success in classifying EEG-based BCI systems. However, DNNs are vulnerable to adversarial attacks using adversarial examples imperceptible to humans. This paper proposes a novel generative model named generative perturbation network (GPN), able to generate adversarial examples by signal-agnostic and signal-specific perturbations for targeted and non-targeted attacks. By modifying the proposed model slightly, we can also generate conditional or total perturbations for an EEG dataset with a pretrained weight. Our experimental evaluation demonstrates that perturbations generated by the proposed model outperform previous approaches for crafting signal-agnostic perturbation in non-targeted and targeted attacks. Moreover, we show that modified models, i.e., conditional and multiple GPN, can generate perturbations of all classification models, attack types, and target classes with single trained parameters only. Finally, we show that the proposed method has higher transferability across classification networks than comparison methods, demonstrating the perturbations are well generalized.

# Architecture
Generative Perturbation Networks (GPNs)
![image](https://user-images.githubusercontent.com/50229148/170930773-a2f59d1a-e5a1-469e-ad7c-b692d3264239.png)

# Result

## Topoplots of adversarial exampels from mGPN
